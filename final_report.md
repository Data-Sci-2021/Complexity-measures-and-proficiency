# Final report
## Rossina Soyan, Fall 2021, ros129@pitt.edu
## Introduction
### Summary
The goal of the project was to understand what lexical complexity measures correspond to intermediate and advanced proficiency levels in L2 Russian texts. To answer this question, I calculated three lexical complexity measures using a small sub-corpus of L2 Russian texts, performed a hierarchical cluster analysis and compared the results with the original proficiency levels. 

### Background/ Motivation
My interest in complexity measures in L2 Russian texts started in the summer of 2019 when I worked as a Russian language instructor at Middlebury Summer Russian School. One of the main elements of this language program is tracking students' progress using the ACTFL scale. After 8 weeks of intensive instruction, some students showed progress as defined by ACTFL, while other did not. What spurred my interest was the desire to see if certain linguistic features correspond to the ACTFL proficiency levels. This line of research may contribute to the automatization of L2 writing assessment in the future. 

### Theoretical background
In this project, L2 writing development is explored through the lens of lexical complexity and is understood as part of a larger framework of writing ability. While the narrow understanding of writing ability includes only grammatical knowledge and discourse aspects, the wider framework, the Writing Competence Model, also recognizes sociolinguistic and strategic competencies, as well as content and source use as essential (Barkaoui & Hadidi, 2020). Exploring all the aspects of the Writing Competence Model would be time-consuming and beyond the scope of the course, therefore, I decided to focus only on one aspect of grammatical competence, that is, *lexical complexity* (LC). 
LC is defined as the range of vocabulary used in a text (variation) and its sophistication (Wolfe-Quintero et al., 1998). LC is a multi-dimensional construct, however, its components are still in the process of negotiation. The majority of LC studies are based on L2 English texts. In this project, I adopted Barkaoui and Hadidi's (2020) understanding of LC which is also based on L2 texts. They distinguish four LC measures: lexical density, lexical variation, lexical sophistication, and lexical bundles. In order to measure lexical bundles, I would need an additional, more representative corpus for comparison, which I do not have access to yet. Therefore, I decided to focus on the other three LC measures. *Lexical density* is understood as the ratio of lexical words to all words per essay. It is believed that the higher lexical density of essays, the higher the proficiency of students. *Lexical variation*, which is also known as lexical density, is operationalized as the ratio of the types to the tokens (TTR). A version of TTR less dependent on text length is Measure of Textual Lexical Diversity (MTLD). The hypothesis is the higher lexical variation of essays, the higher the proficiency of students. *Lexical sophistication* is understood as the proportion of relatively unusual, low-frequency word to frequent words in a text. In English, low-frequency words are longer than high-frequency words, therefore, lexical sophistication is sometimes calculated through average word length (AWL) through dividing the total number of letters by the total number of words. The longer the AWL, the higher the proficiency of students.

## Dataset
To be able to finish the project on time, I only used a sub-corpus of texts from a bigger corpus of L2 Russian essays written by US college students. I randomly chose essays of eight students, four of whom were rated as Intermediate and four as Advanced according to the ACTFL scale. Each student was asked to write three essays as part of their placement in the language program. Therefore, my sub-corpus consists of 24 texts total. Students were expected to write their essays by hand without access to any additional resources. The time limit was 90 minutes. The ACTFL ratings were given by two trained Russian language instructors. A third rater would be invited for the final rating if the first two raters did not agree on the proficiency level. The handwritten essays were digitized by one RA and then checked by another RA. To make texts processable by udpipe, spelling was corrected in all the essays. 

## Overall history, or warts and all
My original goal for this final project was much more ambitious. I wanted to use the whole corpus which includes 601 texts and I wanted to measure not only lexical complexity but also syntactic complexity. From the outset, it turned out that every step would be painful. I started by loading one text and trying to figure out how to calculate each complexity measure. First of all, making sure that the computer loads the text in Cyrillic turned out to be a challenge. I needed to set to the locale, make sure the encoding is specified. Every time I installed a new package, I needed to check if there was an additional package with the Russian language and install the additional package. Another problem was tokenization of hyphenated Russian words which were counted as two separate tokens. When I was done with lexical complexity measures, I tried to load spacyr and udpipe to see how the texts would tagged. I figured out how to load the original packages and the additional packages in Russian, but the output  had too many mistakes and I could not figure out how to count coordinated and subordinated clauses. In the end, I decided to just focus on lexical complexity measures. The final problem was turning the output of the MTLD() function into a dataframe. My coding skills were not sufficient, so I gave up and transferred the numbers manually. Although the final result turned out to be much smaller than my original goals, I am still happy I practiced coding and working with the corpus data. 

## Analysis 
1. I loaded [the sub-corpus to R](https://github.com/Data-Sci-2021/Complexity-measures-and-proficiency/blob/main/final_code.Rmd). 
2. To calculate lexical density, I created five txt files with a possible list of non-lexical words in Russian. I anti-joined non-lexical and lexical words in each essay. Then, I divided the number of lexical words to the total number of words. I came up with a lexical density number for each student based on their three essays.
3. To calculate lexical variation, I installed the koRpus package and measured MTLD for all students. I had to create a vector for MTLD manually. I also measured the TTR for each students' three essays. I did not like the output since the student with the shortest essays was rated as having the most lexically varied texts which seems a bit unfair.
4. To calculate lexical sophistication, I counted the length of each word, added everything up and divided the total length by the total number of words. 
5. I conducted a hierarchical cluster analysis which is defined as "a mathematical procedure for classifying cases (e.g., texts) into groups based on their shared similarities across a number of measures (e.g., linguistic features)‚Äù (Jarvis et al., 2003, p. 384). Following the instructions in the [datacamp tutorial](https://www.datacamp.com/community/tutorials/hierarchical-clustering-R), I scaled my three vectors, performed the hierarchical cluster analysis, and measured the goodness of clusters. 
![This is the resulting dendrogram](https://github.com/Data-Sci-2021/Complexity-measures-and-proficiency/blob/main/final_code_files/figure-gfm/unnamed-chunk-12-1.png)
![This is a version of the dendrogram above with colores](https://github.com/Data-Sci-2021/Complexity-measures-and-proficiency/blob/main/final_code_files/figure-gfm/unnamed-chunk-14-1.png)
6. I interpreted the results. 3 out of 8 students were not in their expected clusters. Despite high MTLD and AWL, two students were rated as Intermediate, although they were advanced. Despite low MTLD and AWL, one student was rated as advanced, although they were intermediate. Why have Students 3, 2, and 7 been chosen for one cluster? The review of raw numbers shows that Students 3, 2, and 7 have the lowest MTLD and AWL. Lexical density was not considered in clustering. 
I have three possible interpretations. First, LC measures do not influence proficiency ratings at intermediate and advanced levels. It is possible that syntactic complexity measures, or discourse and strategic competencies are more important at more advanced levels of proficiency. Second, LC measures relevant for L2 English texts may not be relevant for L2 Russian texts. In different languages, we may need to identify different LC measures reflecting growth in proficiency. Third, these lexical complexity measures may be credible all along and it is the ACTFL proficiency ratings which are inherently flawed. The third interpretation is possible but  unlikely since proficiency ratings are more holistic measures which encompass different dimensions of writing ability, while lexical complexity measures are just one construct within the grammatical competency of writing ability. 
It is difficult to come up with generalizable results from this study since there are many limitations. The corpus size is too small. The tokenization rules should be checked once more. The length of essays which was not controlled in this paper might have skewed the results since there was one student who has written three times less than the other students. The division into lexical and non-lexical items may be revised in the future. I need to read more about non-lexical items in order to be able to explain why pronouns should also be considered non-lexical items in Russian. MTLD should be compared with other TTR measures, such as HD-D or MATTR. While AWL and density are ratios, MTLD is calculated using a formula which covers the resulting numbers with a layer of mysteriousness.  

## Conclusions
Overall, I am glad I worked on this project. I realized that I can code and I can understand how magic LC numbers are calculated. In the future, I see myself trying to work out how to calculate lexical bundles and syntactic complexity measures and assess how relevant they are for proficiency ratings in L2 Russian texts.  

## References
Barkaoui, K., & Hadidi, A. (2020). *Assessing change in English second language writing performance.* Routledge. 
Jarvis, S., Grant, L., Bikowski, D., & Ferris, D. (2003). Exploring multiple profiles of highly rated learner compositions. *Journal of Second Language Writing*, 12(4), 377-403.
Wolfe-Quintero, K., Inagaki, S., & Kim, H.-Y. (1998). *Second language development in writing: Measures of fluency, accuracy, & complexity.* University of Hawai'i.



