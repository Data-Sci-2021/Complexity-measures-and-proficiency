---
title: "Draft_1"
author: "Rossina Soyan"
date: "10/25/2021"
output: 
  github_document: 
    toc: TRUE
---

```{r setup}
##Set knitr options (show both code and output, show output w/o leading #, make figures smaller, hold figures until after chunk)
knitr::opts_chunk$set(echo=TRUE, include=TRUE, comment=NA, fig.height=3, fig.width=4.2, fig.show="hold")

```

## First steps

```{r}
library(tidyverse)
#install.packages('readtext') to read a corpus
library(readtext)
#install.packages('quanteda') to work with a corpus
library(quanteda)
#install.packages("htmlwidgets") to work with strings and regular expressions
library(htmlwidgets)
```


## An attempt to read at least one .txt file

I am using guidelines for readtext from this (source)[https://github.com/quanteda/readtext]

```{r}
text1 <- readtext("data/text1.txt", encoding = "UTF-8")
# I was able to load one text
text1$text
# I want to exclude the words "unclear" from the text
str_detect(text1$text, "unclear")
text1modified <- char_trim(text1$text, "sentences", exclude_pattern = "unclear")
text1modified #Unfortunately, this command excludes whole sentences containing the word unclear. And I want to only exclude the words "unclear."
# Let's try writing a function as in this link (https://stackoverflow.com/questions/35790652/removing-words-featured-in-character-vector-from-string)
stopwords = "unclear"
removeWords <- function(str, stopwords) {
  x <- unlist(strsplit(str, " "))
  paste(x[!x %in% stopwords], collapse = " ")
}
text1mod2 <- removeWords(text1$text, stopwords)
text1mod2 #success! I was able to remove the words "unclear" from the text in Russian.

```

## Complexity measures

Let me try to measure complexity measures in one text. By the way, since I am only working with one text right now, I can actually check the numbers manually.

## Global complexity - Mean sentence length

```{r}
str_length(text1$text) # This is the number of characters in this text with spaces
str_length(text1modified)
str_length(text1mod2) #Yes! It worked
#How do I count the number of sentences?
nsentence(text1$text)
nsentence(text1mod2) #the answers for both texts is 17 but I am not sure what to do with the following warning - Warning in nsentence.character(text1mod2) : nsentence() does not correctly count sentences in all lower-cased text. Can I just ignore it? Another issue is the address in the beginning of the text Дорогая Лара! This is not a real sentence. How do I not count it as a sentence?
#How do I count the number of words in a sentence? 
ntoken(text1$text, remove_punct = TRUE)
ntoken(text1mod2, remove_punct = TRUE) # Now it works!
(MSLtext1 <- ntoken(text1mod2, remove_punct = TRUE)/ nsentence(text1mod2)) # I have an answer except I do not know how to not count the address in the beginning of the text as not a sentence.
```

## Complexity by coordination - T-units per sentence

I am not sure how to count the number of T-units. I think I need to write my own function. If the definition of a sentence is anything which starts with an upper-case letter and ends with a period or ! or ?, then, the definition of a T-unit is a little bit more complex. Based on mt example test, T-unit may start with an upper- or lower-case and it can end before и if there is a subject and a verb after it or end with a period, ?, !.
```{r}
#nTunit <- function(str, )
```

